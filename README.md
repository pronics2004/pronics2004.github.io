# Prasanna Sattigeri

<img src="profile.png" alt="profile" width="200"/>

## About Me

I am a **Principal Research Scientist** at [IBM Research AI](https://research.ibm.com/) and the [MIT-IBM Watson AI Lab](https://mitibmwatsonailab.mit.edu/), where my primary focus is on developing reliable AI solutions.

### Research Interests

My research interests encompass:
- **Generative Modeling** and Large Language Models
- **Uncertainty Quantification** for AI systems
- **Learning with Limited Data**
- **LLM Governance and Safety**

My current projects are focused on establishing both theoretical frameworks and practical systems that ensure large language models are reliable and trustworthy.

### Open-Source Contributions

I have played a significant role in the development of several widely-adopted trustworthy AI toolkits:
- [AI Fairness 360](https://aif360.mybluemix.net/) - Detecting and mitigating bias in ML models
- [AI Explainability 360](https://aix360.mybluemix.net/) - Explaining AI decisions
- [Uncertainty Quantification 360](https://uq360.mybluemix.net/) - Quantifying uncertainty in AI predictions

---

## Links

- [Google Scholar](https://scholar.google.com/citations?hl=en&user=m-s38ikAAAAJ&view_op=list_works)
- [Detailed CV](CV.md)

---

## News

- **June 2024** - Invited talk on LLM Governance and Alignment at the NAACL TrustNLP Workshop. [Slides](slides/naacl_trustnlp_talk.pdf)
- **2024** - Panel participation and talk on Reliable AI-assisted Decision Making at the National Academy of Sciences Decadal Survey
- **August 2023** - Invited talk on Uncertainty Calibration and AI-assisted Decision Making at the Workshop on Uncertainty Reasoning and Quantification in Decision Making, KDD
- **August 2023** - Panel participation and talk on Generative AI and Safety at the DSHealth Workshop, KDD
- **August 2023** - Panel participation on Trustworthy LLMs at the AI for Open Society Day, KDD
